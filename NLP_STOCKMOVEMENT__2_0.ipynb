{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import gensim\n",
    "import wget\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "#from ..utils.data_utils import get_file\n",
    "#from ..preprocessing.sequence import _remove_long_seq\n",
    "import json\n",
    "import warnings\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "## Plot\n",
    "#import plotly.offline as py\n",
    "#import plotly.graph_objs as go\n",
    "#py.init_notebook_mode(connected=True)\n",
    "import matplotlib as plt\n",
    "# Other\n",
    "import re\n",
    "import string\n",
    "from sklearn.manifold import TSNE\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Understanding </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Combined_News_DJIA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
       "      <td>Stephen Hawking says pollution and 'stupidity'...</td>\n",
       "      <td>Boris Johnson says he will not run for Tory pa...</td>\n",
       "      <td>Six gay men in Ivory Coast were abused and for...</td>\n",
       "      <td>Switzerland denies citizenship to Muslim immig...</td>\n",
       "      <td>Palestinian terrorist stabs israeli teen girl ...</td>\n",
       "      <td>Puerto Rico will default on $1 billion of debt...</td>\n",
       "      <td>Republic of Ireland fans to be awarded medal f...</td>\n",
       "      <td>...</td>\n",
       "      <td>Googles free wifi at Indian railway stations i...</td>\n",
       "      <td>Mounting evidence suggests 'hobbits' were wipe...</td>\n",
       "      <td>The men who carried out Tuesday's terror attac...</td>\n",
       "      <td>Calls to suspend Saudi Arabia from UN Human Ri...</td>\n",
       "      <td>More Than 100 Nobel Laureates Call Out Greenpe...</td>\n",
       "      <td>British pedophile sentenced to 85 years in US ...</td>\n",
       "      <td>US permitted 1,200 offshore fracks in Gulf of ...</td>\n",
       "      <td>We will be swimming in ridicule - French beach...</td>\n",
       "      <td>UEFA says no minutes of silence for Istanbul v...</td>\n",
       "      <td>Law Enforcement Sources: Gun Used in Paris Ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
       "      <td>IMF chief backs Athens as permanent Olympic host</td>\n",
       "      <td>The president of France says if Brexit won, so...</td>\n",
       "      <td>British Man Who Must Give Police 24 Hours' Not...</td>\n",
       "      <td>100+ Nobel laureates urge Greenpeace to stop o...</td>\n",
       "      <td>Brazil: Huge spike in number of police killing...</td>\n",
       "      <td>Austria's highest court annuls presidential el...</td>\n",
       "      <td>Facebook wins privacy case, can track any Belg...</td>\n",
       "      <td>...</td>\n",
       "      <td>The United States has placed Myanmar, Uzbekist...</td>\n",
       "      <td>S&amp;amp;P revises European Union credit rating t...</td>\n",
       "      <td>India gets $1 billion loan from World Bank for...</td>\n",
       "      <td>U.S. sailors detained by Iran spoke too much u...</td>\n",
       "      <td>Mass fish kill in Vietnam solved as Taiwan ste...</td>\n",
       "      <td>Philippines president Rodrigo Duterte urges pe...</td>\n",
       "      <td>Spain arrests three Pakistanis accused of prom...</td>\n",
       "      <td>Venezuela, where anger over food shortages is ...</td>\n",
       "      <td>A Hindu temple worker has been killed by three...</td>\n",
       "      <td>Ozone layer hole seems to be healing - US &amp;amp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Label                                               Top1  \\\n",
       "1987  2016-06-30      1  Jamaica proposes marijuana dispensers for tour...   \n",
       "1988  2016-07-01      1  A 117-year-old woman in Mexico City finally re...   \n",
       "\n",
       "                                                   Top2  \\\n",
       "1987  Stephen Hawking says pollution and 'stupidity'...   \n",
       "1988   IMF chief backs Athens as permanent Olympic host   \n",
       "\n",
       "                                                   Top3  \\\n",
       "1987  Boris Johnson says he will not run for Tory pa...   \n",
       "1988  The president of France says if Brexit won, so...   \n",
       "\n",
       "                                                   Top4  \\\n",
       "1987  Six gay men in Ivory Coast were abused and for...   \n",
       "1988  British Man Who Must Give Police 24 Hours' Not...   \n",
       "\n",
       "                                                   Top5  \\\n",
       "1987  Switzerland denies citizenship to Muslim immig...   \n",
       "1988  100+ Nobel laureates urge Greenpeace to stop o...   \n",
       "\n",
       "                                                   Top6  \\\n",
       "1987  Palestinian terrorist stabs israeli teen girl ...   \n",
       "1988  Brazil: Huge spike in number of police killing...   \n",
       "\n",
       "                                                   Top7  \\\n",
       "1987  Puerto Rico will default on $1 billion of debt...   \n",
       "1988  Austria's highest court annuls presidential el...   \n",
       "\n",
       "                                                   Top8  ...  \\\n",
       "1987  Republic of Ireland fans to be awarded medal f...  ...   \n",
       "1988  Facebook wins privacy case, can track any Belg...  ...   \n",
       "\n",
       "                                                  Top16  \\\n",
       "1987  Googles free wifi at Indian railway stations i...   \n",
       "1988  The United States has placed Myanmar, Uzbekist...   \n",
       "\n",
       "                                                  Top17  \\\n",
       "1987  Mounting evidence suggests 'hobbits' were wipe...   \n",
       "1988  S&amp;P revises European Union credit rating t...   \n",
       "\n",
       "                                                  Top18  \\\n",
       "1987  The men who carried out Tuesday's terror attac...   \n",
       "1988  India gets $1 billion loan from World Bank for...   \n",
       "\n",
       "                                                  Top19  \\\n",
       "1987  Calls to suspend Saudi Arabia from UN Human Ri...   \n",
       "1988  U.S. sailors detained by Iran spoke too much u...   \n",
       "\n",
       "                                                  Top20  \\\n",
       "1987  More Than 100 Nobel Laureates Call Out Greenpe...   \n",
       "1988  Mass fish kill in Vietnam solved as Taiwan ste...   \n",
       "\n",
       "                                                  Top21  \\\n",
       "1987  British pedophile sentenced to 85 years in US ...   \n",
       "1988  Philippines president Rodrigo Duterte urges pe...   \n",
       "\n",
       "                                                  Top22  \\\n",
       "1987  US permitted 1,200 offshore fracks in Gulf of ...   \n",
       "1988  Spain arrests three Pakistanis accused of prom...   \n",
       "\n",
       "                                                  Top23  \\\n",
       "1987  We will be swimming in ridicule - French beach...   \n",
       "1988  Venezuela, where anger over food shortages is ...   \n",
       "\n",
       "                                                  Top24  \\\n",
       "1987  UEFA says no minutes of silence for Istanbul v...   \n",
       "1988  A Hindu temple worker has been killed by three...   \n",
       "\n",
       "                                                  Top25  \n",
       "1987  Law Enforcement Sources: Gun Used in Paris Ter...  \n",
       "1988  Ozone layer hole seems to be healing - US &amp...  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Cleaning </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineHeadlines(dataframe):\n",
    "    testheadlines = []\n",
    "    for row in range(0,len(dataframe.index)):\n",
    "        testheadlines.append(' '.join(str(x) for x in dataframe.iloc[row,2:27]))         \n",
    "    return testheadlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combineHeadlines(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data,columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to cleaning text data\n",
    "def clean_text(text):\n",
    "    ## Remove punctuation\n",
    "    #text = text.translate(string.punctuation)\n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    text = \" \".join(text)\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Engineering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['polarity'] = data['text'].map(lambda x: TextBlob(x).sentiment[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['subjectivity'] = data['text'].map(lambda x: TextBlob(x).sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.263"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(data['text'][0])['neg']\n",
    "#print(str(vs))\n",
    "#print(str(vs[\"compound\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['neg'] = data['text'].map(lambda x: analyzer.polarity_scores(x)['neg'])\n",
    "data['neu'] = data['text'].map(lambda x: analyzer.polarity_scores(x)['neu'])\n",
    "data['pos'] = data['text'].map(lambda x: analyzer.polarity_scores(x)['pos'])\n",
    "data['compound'] = data['text'].map(lambda x: analyzer.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>explos airport istanbul yemeni former presid :...</td>\n",
       "      <td>0.122277</td>\n",
       "      <td>0.382513</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.098</td>\n",
       "      <td>-0.9818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>jamaica propos marijuana dispens tourist airpo...</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>0.384982</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>117 - year - old woman mexico citi final recei...</td>\n",
       "      <td>0.063571</td>\n",
       "      <td>0.299821</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.9979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity  \\\n",
       "1986  explos airport istanbul yemeni former presid :...  0.122277   \n",
       "1987  jamaica propos marijuana dispens tourist airpo...  0.047527   \n",
       "1988  117 - year - old woman mexico citi final recei...  0.063571   \n",
       "\n",
       "      subjectivity    neg    neu    pos  compound  \n",
       "1986      0.382513  0.188  0.714  0.098   -0.9818  \n",
       "1987      0.384982  0.235  0.683  0.083   -0.9963  \n",
       "1988      0.299821  0.246  0.693  0.060   -0.9979  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polyglot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d63005cc9b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpolyglot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_languages_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'polyglot'"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "print(downloader.supported_languages_table(\"sentiment2\", 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polyglot\n",
      "Requirement already satisfied: six>=1.7.3 in /anaconda3/lib/python3.7/site-packages (from polyglot) (1.12.0)\n",
      "Collecting PyICU>=1.8 (from polyglot)\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/35/211ffb949c68e688ade7d40426de030a24eaec4b6c45330eeb9c0285f43a/PyICU-2.3.1.tar.gz\n",
      "Requirement already satisfied: wheel>=0.23.0 in /anaconda3/lib/python3.7/site-packages (from polyglot) (0.32.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /anaconda3/lib/python3.7/site-packages (from polyglot) (1.15.4)\n",
      "Collecting morfessor>=2.0.2a1 (from polyglot)\n",
      "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
      "Collecting pycld2>=0.3 (from polyglot)\n",
      "  Using cached https://files.pythonhosted.org/packages/21/77/8525fe5f147bf2819c7c9942c717c4a79b83f8003da1a3847759fb560909/pycld2-0.31.tar.gz\n",
      "Collecting futures>=2.1.6 (from polyglot)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/80/f41cca0ea1ff69bce7e7a7d76182b47bb4e1a494380a532af3e8ee70b9ec/futures-3.1.1-py3-none-any.whl\n",
      "Building wheels for collected packages: PyICU, pycld2\n",
      "  Running setup.py bdist_wheel for PyICU ... \u001b[?25lerror\n",
      "  Complete output from command /anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-install-5swm2igi/PyICU/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-wheel-ozw2efew --python-tag cp37:\n",
      "  (running 'icu-config --version')\n",
      "  \n",
      "  Building PyICU 2.3.1 for ICU 58.2\n",
      "  \n",
      "  (running 'icu-config --cxxflags --cppflags')\n",
      "  Adding CFLAGS=\"-I/anaconda3/include\" from /anaconda3/bin/icu-config\n",
      "  (running 'icu-config --ldflags')\n",
      "  Adding LFLAGS=\"-Wl,-rpath,/anaconda3/lib -L/anaconda3/lib -licui18n -licuuc -licudata\" from /anaconda3/bin/icu-config\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.7-x86_64-3.7\n",
      "  copying PyICU.py -> build/lib.macosx-10.7-x86_64-3.7\n",
      "  creating build/lib.macosx-10.7-x86_64-3.7/icu\n",
      "  copying icu/__init__.py -> build/lib.macosx-10.7-x86_64-3.7/icu\n",
      "  running build_ext\n",
      "  building '_icu' extension\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -I/anaconda3/include/python3.7m -c _icu.cpp -o build/temp.macosx-10.7-x86_64-3.7/_icu.o -I/anaconda3/include -DPYICU_VER=\"2.3.1\"\n",
      "  warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "  In file included from _icu.cpp:27:\n",
      "  ./common.h:38:13: error: unknown type name 'decltype'\n",
      "      typedef decltype(nullptr) nullptr_t;\n",
      "              ^\n",
      "  ./common.h:38:30: error: expected ';' after top level declarator\n",
      "      typedef decltype(nullptr) nullptr_t;\n",
      "                               ^\n",
      "                               ;\n",
      "  In file included from _icu.cpp:27:\n",
      "  In file included from ./common.h:106:\n",
      "  In file included from /anaconda3/include/unicode/unistr.h:33:\n",
      "  /anaconda3/include/unicode/std_string.h:35:10: fatal error: 'string' file not found\n",
      "  #include <string>\n",
      "           ^~~~~~~~\n",
      "  1 warning and 3 errors generated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for PyICU\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for PyICU\n",
      "  Running setup.py bdist_wheel for pycld2 ... \u001b[?25lerror\n",
      "  Complete output from command /anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-install-5swm2igi/pycld2/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-wheel-4n_evyo0 --python-tag cp37:\n",
      "  running bdist_wheel\n",
      "  The [wheel] section is deprecated. Use [bdist_wheel] instead.\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.7-x86_64-3.7\n",
      "  creating build/lib.macosx-10.7-x86_64-3.7/pycld2\n",
      "  copying pycld2/__init__.py -> build/lib.macosx-10.7-x86_64-3.7/pycld2\n",
      "  running build_ext\n",
      "  building 'pycld2._pycld2' extension\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/cld2\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/cld2/internal\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/bindings\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -Icld2/internal -Icld2/public -I/anaconda3/include/python3.7m -c cld2/internal/cldutil.cc -o build/temp.macosx-10.7-x86_64-3.7/cld2/internal/cldutil.o -w -O2 -m64 -fPIC\n",
      "  In file included from cld2/internal/cldutil.cc:20:\n",
      "  In file included from cld2/internal/cldutil.h:25:\n",
      "  In file included from cld2/internal/scoreonescriptspan.h:81:\n",
      "  cld2/internal/compact_lang_det_impl.h:22:10: fatal error: 'vector' file not found\n",
      "  #include <vector>\n",
      "           ^~~~~~~~\n",
      "  1 error generated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for pycld2\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for pycld2\n",
      "Failed to build PyICU pycld2\n",
      "Installing collected packages: PyICU, morfessor, pycld2, futures, polyglot\n",
      "  Running setup.py install for PyICU ... \u001b[?25lerror\n",
      "    Complete output from command /anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-install-5swm2igi/PyICU/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-record-g8ws2nw0/install-record.txt --single-version-externally-managed --compile:\n",
      "    (running 'icu-config --version')\n",
      "    \n",
      "    Building PyICU 2.3.1 for ICU 58.2\n",
      "    \n",
      "    (running 'icu-config --cxxflags --cppflags')\n",
      "    Adding CFLAGS=\"-I/anaconda3/include\" from /anaconda3/bin/icu-config\n",
      "    (running 'icu-config --ldflags')\n",
      "    Adding LFLAGS=\"-Wl,-rpath,/anaconda3/lib -L/anaconda3/lib -licui18n -licuuc -licudata\" from /anaconda3/bin/icu-config\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.macosx-10.7-x86_64-3.7\n",
      "    copying PyICU.py -> build/lib.macosx-10.7-x86_64-3.7\n",
      "    creating build/lib.macosx-10.7-x86_64-3.7/icu\n",
      "    copying icu/__init__.py -> build/lib.macosx-10.7-x86_64-3.7/icu\n",
      "    running build_ext\n",
      "    building '_icu' extension\n",
      "    creating build/temp.macosx-10.7-x86_64-3.7\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -I/anaconda3/include/python3.7m -c _icu.cpp -o build/temp.macosx-10.7-x86_64-3.7/_icu.o -I/anaconda3/include -DPYICU_VER=\"2.3.1\"\n",
      "    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]\n",
      "    In file included from _icu.cpp:27:\n",
      "    ./common.h:38:13: error: unknown type name 'decltype'\n",
      "        typedef decltype(nullptr) nullptr_t;\n",
      "                ^\n",
      "    ./common.h:38:30: error: expected ';' after top level declarator\n",
      "        typedef decltype(nullptr) nullptr_t;\n",
      "                                 ^\n",
      "                                 ;\n",
      "    In file included from _icu.cpp:27:\n",
      "    In file included from ./common.h:106:\n",
      "    In file included from /anaconda3/include/unicode/unistr.h:33:\n",
      "    /anaconda3/include/unicode/std_string.h:35:10: fatal error: 'string' file not found\n",
      "    #include <string>\n",
      "             ^~~~~~~~\n",
      "    1 warning and 3 errors generated.\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCommand \"/anaconda3/bin/python -u -c \"import setuptools, tokenize;__file__='/private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-install-5swm2igi/PyICU/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-record-g8ws2nw0/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /private/var/folders/kj/fchz5ny54lbdzhb7z678qh940000gn/T/pip-install-5swm2igi/PyICU/\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [data,df[['Label','Date']]]\n",
    "#pd.concat(df_list, ignore_index=True)\n",
    "result = pd.concat(df_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b georgia would own two russian warplan countr...</td>\n",
       "      <td>-0.031843</td>\n",
       "      <td>0.307501</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.9970</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b whi wont america nato help us wont help now ...</td>\n",
       "      <td>0.024205</td>\n",
       "      <td>0.281621</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.063</td>\n",
       "      <td>-0.9906</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b are member ador 9 - year - old sang open cer...</td>\n",
       "      <td>-0.125450</td>\n",
       "      <td>0.488944</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.9948</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u s refus israel weapon attack iran : report b...</td>\n",
       "      <td>-0.009991</td>\n",
       "      <td>0.266807</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.9508</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b all expert admit legalis drug b war south os...</td>\n",
       "      <td>0.046292</td>\n",
       "      <td>0.275770</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.9865</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  polarity  subjectivity  \\\n",
       "0  b georgia would own two russian warplan countr... -0.031843      0.307501   \n",
       "1  b whi wont america nato help us wont help now ...  0.024205      0.281621   \n",
       "2  b are member ador 9 - year - old sang open cer... -0.125450      0.488944   \n",
       "3  u s refus israel weapon attack iran : report b... -0.009991      0.266807   \n",
       "4  b all expert admit legalis drug b war south os...  0.046292      0.275770   \n",
       "\n",
       "     neg    neu    pos  compound  Label        Date  \n",
       "0  0.263  0.690  0.047   -0.9970      0  2008-08-08  \n",
       "1  0.247  0.691  0.063   -0.9906      1  2008-08-11  \n",
       "2  0.219  0.747  0.033   -0.9948      0  2008-08-12  \n",
       "3  0.148  0.790  0.061   -0.9508      0  2008-08-13  \n",
       "4  0.210  0.712  0.078   -0.9865      1  2008-08-14  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = result [result['Date']< '2015-01-01']\n",
    "test = result[result['Date']> '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>death toll among qatar 2022 world cup worker r...</td>\n",
       "      <td>-0.135877</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.9921</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>saudi eager await approv new draft law shoura ...</td>\n",
       "      <td>0.059042</td>\n",
       "      <td>0.370119</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.9962</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>solar power storag price drop 25 germani lt;1 ...</td>\n",
       "      <td>0.062917</td>\n",
       "      <td>0.261736</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.9947</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>china businessman jail year buy eat three tige...</td>\n",
       "      <td>0.037854</td>\n",
       "      <td>0.300318</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.9914</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>airasia flight found bottom java sea north kor...</td>\n",
       "      <td>0.018524</td>\n",
       "      <td>0.324903</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.9871</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity  \\\n",
       "1606  death toll among qatar 2022 world cup worker r... -0.135877   \n",
       "1607  saudi eager await approv new draft law shoura ...  0.059042   \n",
       "1608  solar power storag price drop 25 germani lt;1 ...  0.062917   \n",
       "1609  china businessman jail year buy eat three tige...  0.037854   \n",
       "1610  airasia flight found bottom java sea north kor...  0.018524   \n",
       "\n",
       "      subjectivity    neg    neu    pos  compound  Label        Date  \n",
       "1606      0.285000  0.168  0.818  0.014   -0.9921      1  2014-12-24  \n",
       "1607      0.370119  0.233  0.690  0.076   -0.9962      1  2014-12-26  \n",
       "1608      0.261736  0.232  0.710  0.057   -0.9947      0  2014-12-29  \n",
       "1609      0.300318  0.173  0.778  0.050   -0.9914      0  2014-12-30  \n",
       "1610      0.324903  0.141  0.834  0.024   -0.9871      0  2014-12-31  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> MODELING </H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Word2Vec</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "#model = KeyedVectors.load_word2vec_format(filename, binary=True) what is the diff with below one?\n",
    "#word2vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label\n",
       "686       1\n",
       "1535      1\n",
       "751       0\n",
       "96        1\n",
       "178       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['text','polarity','subjectivity','Label','Date','neg','neu','pos','compound']\n",
    "X = train[columns]\n",
    "Y = train[\"Label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20,random_state=0)\n",
    "y_train_t = pd.DataFrame(y_train,columns=[\"Label\"])\n",
    "\n",
    "y_train_t.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamsuarez/anaconda2/envs/pandas_env/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "X_train[\"tokens\"] = X_train[\"text\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>franc drop concret bomb libya tunisian armi en...</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.351971</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.9959</td>\n",
       "      <td>[franc, drop, concret, bomb, libya, tunisian, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>former auschwitz guard 93 charg accessori 300 ...</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.290256</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.9834</td>\n",
       "      <td>[former, auschwitz, guard, 93, charg, accessor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>israel agre negoti pre - 67 line fatal radiat ...</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>0.414103</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-08-02</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.9922</td>\n",
       "      <td>[israel, agre, negoti, pre, 67, line, fatal, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>b hell earth citi shipbreak b full text irania...</td>\n",
       "      <td>0.162527</td>\n",
       "      <td>0.393398</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-24</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.9638</td>\n",
       "      <td>[b, hell, earth, citi, shipbreak, b, full, tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>b i think peopl need understand waterboard is ...</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.342647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-04-24</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.9922</td>\n",
       "      <td>[b, i, think, peopl, need, understand, waterbo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity  \\\n",
       "686   franc drop concret bomb libya tunisian armi en...  0.002997   \n",
       "1535  former auschwitz guard 93 charg accessori 300 ... -0.005350   \n",
       "751   israel agre negoti pre - 67 line fatal radiat ...  0.031293   \n",
       "96    b hell earth citi shipbreak b full text irania...  0.162527   \n",
       "178   b i think peopl need understand waterboard is ...  0.052139   \n",
       "\n",
       "      subjectivity  Label        Date    neg    neu    pos  compound  \\\n",
       "686       0.351971      1  2011-04-29  0.221  0.727  0.051   -0.9959   \n",
       "1535      0.290256      1  2014-09-15  0.133  0.825  0.041   -0.9834   \n",
       "751       0.414103      0  2011-08-02  0.168  0.810  0.023   -0.9922   \n",
       "96        0.393398      1  2008-12-24  0.198  0.682  0.120   -0.9638   \n",
       "178       0.342647      1  2009-04-24  0.220  0.705  0.076   -0.9922   \n",
       "\n",
       "                                                 tokens  \n",
       "686   [franc, drop, concret, bomb, libya, tunisian, ...  \n",
       "1535  [former, auschwitz, guard, 93, charg, accessor...  \n",
       "751   [israel, agre, negoti, pre, 67, line, fatal, r...  \n",
       "96    [b, hell, earth, citi, shipbreak, b, full, tex...  \n",
       "178   [b, i, think, peopl, need, understand, waterbo...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max words\n",
    "max_words = X_train['tokens'].apply(lambda x: len(x))\n",
    "max(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-19 23:59:45,355 : INFO : collecting all words and their counts\n",
      "2019-09-19 23:59:45,358 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-09-19 23:59:45,547 : INFO : collected 19677 word types from a corpus of 396584 raw words and 1288 sentences\n",
      "2019-09-19 23:59:45,549 : INFO : Loading a fresh vocabulary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-19 23:59:45,581 : INFO : effective_min_count=40 retains 1928 unique words (9% of original 19677, drops 17749)\n",
      "2019-09-19 23:59:45,583 : INFO : effective_min_count=40 leaves 310545 word corpus (78% of original 396584, drops 86039)\n",
      "2019-09-19 23:59:45,591 : INFO : deleting the raw counts dictionary of 19677 items\n",
      "2019-09-19 23:59:45,596 : INFO : sample=0.001 downsamples 31 most-common words\n",
      "2019-09-19 23:59:45,598 : INFO : downsampling leaves estimated 294014 word corpus (94.7% of prior 310545)\n",
      "2019-09-19 23:59:45,614 : INFO : estimated required memory for 1928 words and 500 dimensions: 8676000 bytes\n",
      "2019-09-19 23:59:45,615 : INFO : resetting layer weights\n",
      "2019-09-19 23:59:45,666 : INFO : training model with 4 workers on 1928 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-09-19 23:59:46,126 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-19 23:59:46,153 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 23:59:46,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 23:59:46,183 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 23:59:46,188 : INFO : EPOCH - 1 : training on 396584 raw words (294029 effective words) took 0.5s, 572828 effective words/s\n",
      "2019-09-19 23:59:46,768 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-19 23:59:46,791 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 23:59:46,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 23:59:46,835 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 23:59:46,837 : INFO : EPOCH - 2 : training on 396584 raw words (293829 effective words) took 0.6s, 461808 effective words/s\n",
      "2019-09-19 23:59:47,657 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-19 23:59:47,665 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 23:59:47,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 23:59:47,677 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 23:59:47,680 : INFO : EPOCH - 3 : training on 396584 raw words (294150 effective words) took 0.8s, 351241 effective words/s\n",
      "2019-09-19 23:59:48,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-19 23:59:48,299 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 23:59:48,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 23:59:48,322 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 23:59:48,323 : INFO : EPOCH - 4 : training on 396584 raw words (294017 effective words) took 0.6s, 460524 effective words/s\n",
      "2019-09-19 23:59:48,930 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-09-19 23:59:48,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-09-19 23:59:48,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-09-19 23:59:48,974 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-19 23:59:48,976 : INFO : EPOCH - 5 : training on 396584 raw words (294074 effective words) took 0.6s, 459068 effective words/s\n",
      "2019-09-19 23:59:48,977 : INFO : training on a 1982920 raw words (1470099 effective words) took 3.3s, 444285 effective words/s\n",
      "2019-09-19 23:59:48,979 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-09-19 23:59:48,985 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2019-09-19 23:59:48,988 : INFO : not storing attribute vectors_norm\n",
      "2019-09-19 23:59:48,992 : INFO : not storing attribute cum_table\n",
      "2019-09-19 23:59:49,047 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "# Set values for various parameters\n",
    "num_features = 500    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print (\"Training model...\")\n",
    "model = word2vec.Word2Vec(X_train['tokens'], workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamsuarez/anaconda2/envs/pandas_env/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/williamsuarez/anaconda2/envs/pandas_env/lib/python2.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'canadian'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"canadian deep space\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "        if counter%500. == 0.:\n",
    "            print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "        reviewFeatureVecs[int(counter)] = makeFeatureVec(review, model, num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "        counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamsuarez/anaconda2/envs/pandas_env/lib/python2.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 1288\n",
      "Review 500 of 1288\n",
      "Review 1000 of 1288\n"
     ]
    }
   ],
   "source": [
    "X_train_Vec = getAvgFeatureVecs(X_train['tokens'], model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "num_classes = 1\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(101, input_shape=(max_words,)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 500)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Label</th>\n",
       "      <th>Date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>franc drop concret bomb libya tunisian armi en...</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.351971</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.9959</td>\n",
       "      <td>[franc, drop, concret, bomb, libya, tunisian, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>former auschwitz guard 93 charg accessori 300 ...</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.290256</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-15</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.9834</td>\n",
       "      <td>[former, auschwitz, guard, 93, charg, accessor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>israel agre negoti pre - 67 line fatal radiat ...</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>0.414103</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-08-02</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.9922</td>\n",
       "      <td>[israel, agre, negoti, pre, 67, line, fatal, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>b hell earth citi shipbreak b full text irania...</td>\n",
       "      <td>0.162527</td>\n",
       "      <td>0.393398</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-12-24</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.9638</td>\n",
       "      <td>[b, hell, earth, citi, shipbreak, b, full, tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>b i think peopl need understand waterboard is ...</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.342647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-04-24</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.9922</td>\n",
       "      <td>[b, i, think, peopl, need, understand, waterbo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity  \\\n",
       "686   franc drop concret bomb libya tunisian armi en...  0.002997   \n",
       "1535  former auschwitz guard 93 charg accessori 300 ... -0.005350   \n",
       "751   israel agre negoti pre - 67 line fatal radiat ...  0.031293   \n",
       "96    b hell earth citi shipbreak b full text irania...  0.162527   \n",
       "178   b i think peopl need understand waterboard is ...  0.052139   \n",
       "\n",
       "      subjectivity  Label        Date    neg    neu    pos  compound  \\\n",
       "686       0.351971      1  2011-04-29  0.221  0.727  0.051   -0.9959   \n",
       "1535      0.290256      1  2014-09-15  0.133  0.825  0.041   -0.9834   \n",
       "751       0.414103      0  2011-08-02  0.168  0.810  0.023   -0.9922   \n",
       "96        0.393398      1  2008-12-24  0.198  0.682  0.120   -0.9638   \n",
       "178       0.342647      1  2009-04-24  0.220  0.705  0.076   -0.9922   \n",
       "\n",
       "                                                 tokens  \n",
       "686   [franc, drop, concret, bomb, libya, tunisian, ...  \n",
       "1535  [former, auschwitz, guard, 93, charg, accessor...  \n",
       "751   [israel, agre, negoti, pre, 67, line, fatal, r...  \n",
       "96    [b, hell, earth, citi, shipbreak, b, full, tex...  \n",
       "178   [b, i, think, peopl, need, understand, waterbo...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 2\n",
    "history = model2.fit(X_train_Vec, np.array(y_train_t['Label']), batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datatest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-88ac2a5de165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datatest' is not defined"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(datatest, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamsuarez/anaconda2/envs/pandas_env/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "XtrainVec =  X_train['text'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamsuarez/anaconda2/envs/pandas_env/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "XtestVec =  X_test['text'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtrainVec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanceVectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "advancedtrain = advanceVectorizer.fit_transform(XtrainVec)\n",
    "#advancedtest = advanceVectorizer.transform(XtestVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedtrain.shape\n",
    "advancedtrain= advancedtrain.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_advanced_train=pd.DataFrame(data=advancedtrain[0:,0:],\n",
    "                   index=[i for i in range(advancedtrain.shape[0])],\n",
    "                   columns=[''+str(i) for i in range(advancedtrain.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>283814</th>\n",
       "      <th>283815</th>\n",
       "      <th>283816</th>\n",
       "      <th>283817</th>\n",
       "      <th>283818</th>\n",
       "      <th>283819</th>\n",
       "      <th>283820</th>\n",
       "      <th>283821</th>\n",
       "      <th>283822</th>\n",
       "      <th>283823</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 283824 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  283814  283815  283816  283817  283818  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...       0       0       0       0       0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...       0       0       0       0       0   \n",
       "\n",
       "   283819  283820  283821  283822  283823  \n",
       "0       0       0       0       0       0  \n",
       "1       0       0       0       0       0  \n",
       "\n",
       "[2 rows x 283824 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_advanced_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = advanceVectorizer.transform(XtestVec)\n",
    "advancedtest= test_dataset.todense()\n",
    "new_advanced_test=pd.DataFrame(data=advancedtest[0:,0:],\n",
    "                   index=[i for i in range(advancedtest.shape[0])],\n",
    "                   columns=[''+str(i) for i in range(advancedtest.shape[1])])\n",
    "#X_train['textVec'] = list(advancedtrain.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1288, 283824)\n",
      "(323, 283824)\n"
     ]
    }
   ],
   "source": [
    "print(new_advanced_train.shape)\n",
    "print(new_advanced_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pd.DataFrame()\n",
    "new_train['polarity'] = X_train['polarity']\n",
    "new_train['subjectivity'] = X_train['subjectivity']\n",
    "new_train['neg'] = X_train['neg']\n",
    "new_train['neu'] = X_train['neu']\n",
    "new_train['pos'] = X_train['pos']\n",
    "new_train['compound'] = X_train['compound']\n",
    "new_test = pd.DataFrame()\n",
    "new_test['polarity'] = X_test['polarity']\n",
    "new_test['subjectivity'] = X_test['subjectivity']\n",
    "new_test['neg'] = X_test['neg']\n",
    "new_test['neu'] = X_test['neu']\n",
    "new_test['pos'] = X_test['pos']\n",
    "new_test['compound'] = X_test['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = new_train.reset_index()\n",
    "new_test = new_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>686</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.351971</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.9959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1535</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.290256</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.9834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>751</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>0.414103</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96</td>\n",
       "      <td>0.162527</td>\n",
       "      <td>0.393398</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.120</td>\n",
       "      <td>-0.9638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178</td>\n",
       "      <td>0.052139</td>\n",
       "      <td>0.342647</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.9922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  polarity  subjectivity    neg    neu    pos  compound\n",
       "0    686  0.002997      0.351971  0.221  0.727  0.051   -0.9959\n",
       "1   1535 -0.005350      0.290256  0.133  0.825  0.041   -0.9834\n",
       "2    751  0.031293      0.414103  0.168  0.810  0.023   -0.9922\n",
       "3     96  0.162527      0.393398  0.198  0.682  0.120   -0.9638\n",
       "4    178  0.052139      0.342647  0.220  0.705  0.076   -0.9922"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_advanced_train['polarity'] = new_train['polarity']\n",
    "new_advanced_train['subjectivity'] = new_train['subjectivity']\n",
    "new_advanced_train['neg'] = new_train['neg']\n",
    "new_advanced_train['neu'] = new_train['neu']\n",
    "new_advanced_train['pos'] = new_train['pos']\n",
    "new_advanced_train['compound'] = new_train['compound']\n",
    "\n",
    "new_advanced_test['polarity'] = new_test['polarity']\n",
    "new_advanced_test['subjectivity'] = new_test['subjectivity']\n",
    "new_advanced_test['neg'] = new_test['neg']\n",
    "new_advanced_test['neu'] = new_test['neu']\n",
    "new_advanced_test['pos'] = new_test['pos']\n",
    "new_advanced_test['compound'] = new_test['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1288, 283830)\n",
      "(323, 283830)\n"
     ]
    }
   ],
   "source": [
    "print(new_advanced_train.shape)\n",
    "print(new_advanced_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test['textVec'] = list(test_dataset.toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators = 200,criterion='entropy',oob_score = True, n_jobs = -1,random_state =50,max_features = \"auto\", min_samples_leaf = 50)\n",
    "randomforest = randomforest.fit(new_advanced_train, y_train_t[\"Label\"])\n",
    "predictions = randomforest.predict(new_advanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_t = pd.DataFrame(y_test,columns=[\"Label\"])\n",
    "score = accuracy_score(y_test_t['Label'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.82%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (score * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['polarity','subjectivity','neg','neu','pos','compound']\n",
    "new_advanced_train2= new_advanced_train[columns]\n",
    "new_advanced_test2= new_advanced_test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "xgb_model = xgb_model.fit(new_advanced_train2, y_train_t[\"Label\"])\n",
    "advancedprediction = xgb_model.predict(new_advanced_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(value) for value in advancedprediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.18%\n"
     ]
    }
   ],
   "source": [
    "#evaluate predictions\n",
    "accuracy = accuracy_score(y_test_t['Label'], predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning:\n",
      "\n",
      "Series.base is deprecated and will be removed in a future version\n",
      "\n",
      "/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning:\n",
      "\n",
      "Series.base is deprecated and will be removed in a future version\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "xgb_model = xgb_model.fit(new_advanced_train, y_train_t[\"Label\"])\n",
    "advancedprediction = xgb_model.predict(new_advanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n",
    "xgb_model = xgb_model.fit(X_train_polarity, y_train_t[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedprediction = xgb_model.predict(X_test_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(value) for value in advancedprediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.49%\n"
     ]
    }
   ],
   "source": [
    "#evaluate predictions\n",
    "accuracy = accuracy_score(y_test_t['Label'], predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators = 200,criterion='entropy')\n",
    "randomforest = randomforest.fit(X_train_polarity, y_train_t[\"Label\"])\n",
    "predictions = randomforest.predict(X_test_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(y_test_t['Label'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (score * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
